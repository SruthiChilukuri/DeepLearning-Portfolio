{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " pyTorch_for_LeNet",
      "provenance": [],
      "authorship_tag": "ABX9TyM4nnWF7N8gqVTaUb5g89op",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sruthi1996/DeepLearning/blob/master/pyTorch_for_LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJIERCoRIZSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzHvZf6bIem-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, fwd):\n",
        "        fwd = F.max_pool2d(F.relu(self.conv1(fwd)), 2)\n",
        "        fwd = F.max_pool2d(F.relu(self.conv2(fwd)), 2)\n",
        "        fwd = fwd.view(fwd.size()[0], -1)\n",
        "        fwd = F.relu(self.fc1(fwd))\n",
        "        fwd = F.relu(self.fc2(fwd))\n",
        "        fwd = self.fc3(fwd)\n",
        "        return fwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb-YFP0fIihR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(train_batch_size, test_batch_size):\n",
        "    train_data = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('data', train=True, download=True, transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), \n",
        "                                                                                        transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "        batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    test_data = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('data', train=False, transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), \n",
        "                                                                          transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "        batch_size=test_batch_size, shuffle=True)\n",
        "\n",
        "    return (train_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1qSY53oIlSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, epoch, train_data, log_interval):\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    for batch_idx, (data, target) in enumerate(train_data):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train set, Epoch {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_data.dataset),\n",
        "                       100. * batch_idx / len(train_data),\n",
        "                loss.data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ObdN0oInx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, epoch, test_data):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
        "    for data, target in test_data:\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output, target).data\n",
        "        pred = np.argmax(output.data, axis=1)\n",
        "        correct = correct + np.equal(pred, target.data).sum()\n",
        "\n",
        "    test_loss /= len(test_data.dataset)\n",
        "    print('\\nTest set, Epoch {} , Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(epoch,\n",
        "        test_loss, correct, len(test_data.dataset),\n",
        "        100. * correct / len(test_data.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu_5NR2OIqLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd5f8b36-c019-4b0a-c801-6aa0078cced6"
      },
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model = LeNet()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.1)\n",
        "train_data, test_data = load_data(64, 1000)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs):\n",
        "    train(model, optimizer, epoch, train_data, log_interval=100)\n",
        "    test(model, epoch, test_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set, Epoch 1 [0/60000 (0%)]\tLoss: 2.297229\n",
            "Train set, Epoch 1 [6400/60000 (11%)]\tLoss: 2.274347\n",
            "Train set, Epoch 1 [12800/60000 (21%)]\tLoss: 1.883281\n",
            "Train set, Epoch 1 [19200/60000 (32%)]\tLoss: 0.538160\n",
            "Train set, Epoch 1 [25600/60000 (43%)]\tLoss: 0.563165\n",
            "Train set, Epoch 1 [32000/60000 (53%)]\tLoss: 0.498479\n",
            "Train set, Epoch 1 [38400/60000 (64%)]\tLoss: 0.418060\n",
            "Train set, Epoch 1 [44800/60000 (75%)]\tLoss: 0.251130\n",
            "Train set, Epoch 1 [51200/60000 (85%)]\tLoss: 0.176363\n",
            "Train set, Epoch 1 [57600/60000 (96%)]\tLoss: 0.215318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set, Epoch 1 , Average loss: 0.2280, Accuracy: 9306/10000 (93%)\n",
            "\n",
            "Train set, Epoch 2 [0/60000 (0%)]\tLoss: 0.188753\n",
            "Train set, Epoch 2 [6400/60000 (11%)]\tLoss: 0.106249\n",
            "Train set, Epoch 2 [12800/60000 (21%)]\tLoss: 0.386495\n",
            "Train set, Epoch 2 [19200/60000 (32%)]\tLoss: 0.194581\n",
            "Train set, Epoch 2 [25600/60000 (43%)]\tLoss: 0.148944\n",
            "Train set, Epoch 2 [32000/60000 (53%)]\tLoss: 0.130499\n",
            "Train set, Epoch 2 [38400/60000 (64%)]\tLoss: 0.188583\n",
            "Train set, Epoch 2 [44800/60000 (75%)]\tLoss: 0.101251\n",
            "Train set, Epoch 2 [51200/60000 (85%)]\tLoss: 0.132225\n",
            "Train set, Epoch 2 [57600/60000 (96%)]\tLoss: 0.140846\n",
            "\n",
            "Test set, Epoch 2 , Average loss: 0.1600, Accuracy: 9506/10000 (95%)\n",
            "\n",
            "Train set, Epoch 3 [0/60000 (0%)]\tLoss: 0.217412\n",
            "Train set, Epoch 3 [6400/60000 (11%)]\tLoss: 0.057313\n",
            "Train set, Epoch 3 [12800/60000 (21%)]\tLoss: 0.116542\n",
            "Train set, Epoch 3 [19200/60000 (32%)]\tLoss: 0.104386\n",
            "Train set, Epoch 3 [25600/60000 (43%)]\tLoss: 0.098125\n",
            "Train set, Epoch 3 [32000/60000 (53%)]\tLoss: 0.076716\n",
            "Train set, Epoch 3 [38400/60000 (64%)]\tLoss: 0.215621\n",
            "Train set, Epoch 3 [44800/60000 (75%)]\tLoss: 0.047800\n",
            "Train set, Epoch 3 [51200/60000 (85%)]\tLoss: 0.039468\n",
            "Train set, Epoch 3 [57600/60000 (96%)]\tLoss: 0.065106\n",
            "\n",
            "Test set, Epoch 3 , Average loss: 0.0835, Accuracy: 9739/10000 (97%)\n",
            "\n",
            "Train set, Epoch 4 [0/60000 (0%)]\tLoss: 0.067426\n",
            "Train set, Epoch 4 [6400/60000 (11%)]\tLoss: 0.069230\n",
            "Train set, Epoch 4 [12800/60000 (21%)]\tLoss: 0.039589\n",
            "Train set, Epoch 4 [19200/60000 (32%)]\tLoss: 0.288739\n",
            "Train set, Epoch 4 [25600/60000 (43%)]\tLoss: 0.148584\n",
            "Train set, Epoch 4 [32000/60000 (53%)]\tLoss: 0.050831\n",
            "Train set, Epoch 4 [38400/60000 (64%)]\tLoss: 0.045995\n",
            "Train set, Epoch 4 [44800/60000 (75%)]\tLoss: 0.167143\n",
            "Train set, Epoch 4 [51200/60000 (85%)]\tLoss: 0.129222\n",
            "Train set, Epoch 4 [57600/60000 (96%)]\tLoss: 0.070373\n",
            "\n",
            "Test set, Epoch 4 , Average loss: 0.0763, Accuracy: 9770/10000 (98%)\n",
            "\n",
            "Train set, Epoch 5 [0/60000 (0%)]\tLoss: 0.083476\n",
            "Train set, Epoch 5 [6400/60000 (11%)]\tLoss: 0.056422\n",
            "Train set, Epoch 5 [12800/60000 (21%)]\tLoss: 0.048085\n",
            "Train set, Epoch 5 [19200/60000 (32%)]\tLoss: 0.058329\n",
            "Train set, Epoch 5 [25600/60000 (43%)]\tLoss: 0.191442\n",
            "Train set, Epoch 5 [32000/60000 (53%)]\tLoss: 0.065189\n",
            "Train set, Epoch 5 [38400/60000 (64%)]\tLoss: 0.110727\n",
            "Train set, Epoch 5 [44800/60000 (75%)]\tLoss: 0.062960\n",
            "Train set, Epoch 5 [51200/60000 (85%)]\tLoss: 0.161833\n",
            "Train set, Epoch 5 [57600/60000 (96%)]\tLoss: 0.047475\n",
            "\n",
            "Test set, Epoch 5 , Average loss: 0.0695, Accuracy: 9771/10000 (98%)\n",
            "\n",
            "Train set, Epoch 6 [0/60000 (0%)]\tLoss: 0.037237\n",
            "Train set, Epoch 6 [6400/60000 (11%)]\tLoss: 0.094591\n",
            "Train set, Epoch 6 [12800/60000 (21%)]\tLoss: 0.018597\n",
            "Train set, Epoch 6 [19200/60000 (32%)]\tLoss: 0.062023\n",
            "Train set, Epoch 6 [25600/60000 (43%)]\tLoss: 0.103652\n",
            "Train set, Epoch 6 [32000/60000 (53%)]\tLoss: 0.028828\n",
            "Train set, Epoch 6 [38400/60000 (64%)]\tLoss: 0.038096\n",
            "Train set, Epoch 6 [44800/60000 (75%)]\tLoss: 0.024394\n",
            "Train set, Epoch 6 [51200/60000 (85%)]\tLoss: 0.138446\n",
            "Train set, Epoch 6 [57600/60000 (96%)]\tLoss: 0.018207\n",
            "\n",
            "Test set, Epoch 6 , Average loss: 0.0606, Accuracy: 9793/10000 (98%)\n",
            "\n",
            "Train set, Epoch 7 [0/60000 (0%)]\tLoss: 0.112417\n",
            "Train set, Epoch 7 [6400/60000 (11%)]\tLoss: 0.057851\n",
            "Train set, Epoch 7 [12800/60000 (21%)]\tLoss: 0.136145\n",
            "Train set, Epoch 7 [19200/60000 (32%)]\tLoss: 0.054664\n",
            "Train set, Epoch 7 [25600/60000 (43%)]\tLoss: 0.081667\n",
            "Train set, Epoch 7 [32000/60000 (53%)]\tLoss: 0.014915\n",
            "Train set, Epoch 7 [38400/60000 (64%)]\tLoss: 0.030303\n",
            "Train set, Epoch 7 [44800/60000 (75%)]\tLoss: 0.126728\n",
            "Train set, Epoch 7 [51200/60000 (85%)]\tLoss: 0.045341\n",
            "Train set, Epoch 7 [57600/60000 (96%)]\tLoss: 0.053120\n",
            "\n",
            "Test set, Epoch 7 , Average loss: 0.0564, Accuracy: 9811/10000 (98%)\n",
            "\n",
            "Train set, Epoch 8 [0/60000 (0%)]\tLoss: 0.017923\n",
            "Train set, Epoch 8 [6400/60000 (11%)]\tLoss: 0.035145\n",
            "Train set, Epoch 8 [12800/60000 (21%)]\tLoss: 0.010236\n",
            "Train set, Epoch 8 [19200/60000 (32%)]\tLoss: 0.034710\n",
            "Train set, Epoch 8 [25600/60000 (43%)]\tLoss: 0.091671\n",
            "Train set, Epoch 8 [32000/60000 (53%)]\tLoss: 0.075835\n",
            "Train set, Epoch 8 [38400/60000 (64%)]\tLoss: 0.036488\n",
            "Train set, Epoch 8 [44800/60000 (75%)]\tLoss: 0.063414\n",
            "Train set, Epoch 8 [51200/60000 (85%)]\tLoss: 0.011957\n",
            "Train set, Epoch 8 [57600/60000 (96%)]\tLoss: 0.013117\n",
            "\n",
            "Test set, Epoch 8 , Average loss: 0.0439, Accuracy: 9863/10000 (99%)\n",
            "\n",
            "Train set, Epoch 9 [0/60000 (0%)]\tLoss: 0.035500\n",
            "Train set, Epoch 9 [6400/60000 (11%)]\tLoss: 0.033318\n",
            "Train set, Epoch 9 [12800/60000 (21%)]\tLoss: 0.027102\n",
            "Train set, Epoch 9 [19200/60000 (32%)]\tLoss: 0.117412\n",
            "Train set, Epoch 9 [25600/60000 (43%)]\tLoss: 0.031805\n",
            "Train set, Epoch 9 [32000/60000 (53%)]\tLoss: 0.056160\n",
            "Train set, Epoch 9 [38400/60000 (64%)]\tLoss: 0.004733\n",
            "Train set, Epoch 9 [44800/60000 (75%)]\tLoss: 0.029350\n",
            "Train set, Epoch 9 [51200/60000 (85%)]\tLoss: 0.084406\n",
            "Train set, Epoch 9 [57600/60000 (96%)]\tLoss: 0.126309\n",
            "\n",
            "Test set, Epoch 9 , Average loss: 0.0519, Accuracy: 9832/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
