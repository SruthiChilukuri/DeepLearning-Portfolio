{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmazonPlanetModelWithKeras",
      "provenance": [],
      "authorship_tag": "ABX9TyNZDZSZuQx5+IaixO8N+7X1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sruthi1996/DeepLearning/blob/master/AmazonPlanetModelWithKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhuTnK87D-ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQFdyS0CEMqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0StyH4OdETBp",
        "colab_type": "text"
      },
      "source": [
        "###About the dataset\n",
        "\n",
        "Dataset used to understand the planet from space. The dataset was taken from kaggle. Contains Train and Test datasets; each as an image name feature as well as set of tags that describe that image; seperated by whitespace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqwTXxeKERNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ys1GJXsE5yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras as k\n",
        "#from keras.models import Sequentially\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSwW5n3WFi2S",
        "colab_type": "code",
        "outputId": "d08be534-99eb-47ba-9ba1-24d3e2a6edec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorboard.plugins.hparams import api_pb2\n",
        "from keras.callbacks import TensorBoard\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "from tensorboard.plugins.hparams import summary as hparams_summary\n",
        "from google.protobuf import struct_pb2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHntOBbdFni2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y9jJOvMJrGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id':\"1r874VVhJ7eeerIFgZ9ulX79BoRR6QKeW\"})\n",
        "download.GetContentFile('sample_submission_v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3w8oLjwKI3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_test = pd.read_csv('sample_submission_v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UCWXW03KSBC",
        "colab_type": "code",
        "outputId": "fe314b09-3d9e-4872-8c1d-ae82550cd60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "data_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61186</th>\n",
              "      <td>file_9995</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61187</th>\n",
              "      <td>file_9996</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61188</th>\n",
              "      <td>file_9997</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61189</th>\n",
              "      <td>file_9998</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61190</th>\n",
              "      <td>file_9999</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61191 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_name                                  tags\n",
              "0         test_0  primary clear agriculture road water\n",
              "1         test_1  primary clear agriculture road water\n",
              "2         test_2  primary clear agriculture road water\n",
              "3         test_3  primary clear agriculture road water\n",
              "4         test_4  primary clear agriculture road water\n",
              "...          ...                                   ...\n",
              "61186  file_9995  primary clear agriculture road water\n",
              "61187  file_9996  primary clear agriculture road water\n",
              "61188  file_9997  primary clear agriculture road water\n",
              "61189  file_9998  primary clear agriculture road water\n",
              "61190  file_9999  primary clear agriculture road water\n",
              "\n",
              "[61191 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNUkjqkELFYm",
        "colab_type": "code",
        "outputId": "d1986119-eb7e-4e7e-868f-7181307cb95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "data_test.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 61191 entries, 0 to 61190\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   image_name  61191 non-null  object\n",
            " 1   tags        61191 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 956.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMPwMTLbd9h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id':\"172L8Cep0u2EUUwtorzm8ZfWhrDDEi3Z6\"})\n",
        "download.GetContentFile('train_v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EzM_q8TeJse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_train = pd.read_csv('train_v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MZzVSvQfPc7",
        "colab_type": "code",
        "outputId": "b7915fee-6b43-429d-9050-f2f77fe94c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "data_train.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>haze primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>agriculture clear primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_name                             tags\n",
              "0    train_0                     haze primary\n",
              "1    train_1  agriculture clear primary water\n",
              "2    train_2                    clear primary"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZh-ShutKcfS",
        "colab_type": "text"
      },
      "source": [
        "Seperating the tags for each image; using ' ' separater; thus forming labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur25a3zOfZZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "link = 'https://drive.google.com/open?id=1P6zyoQ7ws6rdrkFj9RUtODrLLNykxXJ4'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('train-jpg.zip')\n",
        "\n",
        "with zipfile.ZipFile('train-jpg.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu-SvdvxfpYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "labels = data_train['tags'].str.get_dummies(sep=' ').columns\n",
        "x_test = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuLD7ctYomw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(layer):\n",
        "    result = []\n",
        "    for sublist in layer:     \n",
        "        for item in sublist: \n",
        "            result.append(item)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDwjSahBopoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labs = list(set(flatten([layer.split(' ') for layer in data_train['tags'].values])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgTFGrDvosNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab_max = {layer: i for i, layer in enumerate(labs)}\n",
        "inv_lab_max = {i: layer for layer, i in lab_max.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq73loMMou1g",
        "colab_type": "code",
        "outputId": "9c154eac-bed1-4de9-9483-bb4c5a464a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for f, tags in tqdm(data_train.values, miniters=5000):\n",
        "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
        "    targets = np.zeros(17)\n",
        "    for t in tags.split(' '):\n",
        "        targets[lab_max[t]] = 1 \n",
        "    x_train.append(cv2.resize(img, (32, 32)))\n",
        "    y_train.append(targets)\n",
        "    \n",
        "y_train = np.array(y_train, np.uint8)\n",
        "x_train = np.array(x_train, np.float16) / 255."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40479/40479 [00:46<00:00, 866.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGhfUjn0PXOH",
        "colab_type": "text"
      },
      "source": [
        "Split train and test into test as 10000 images and train data as rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw1A8E9xpSwZ",
        "colab_type": "code",
        "outputId": "cbd25996-6344-41ac-844b-dd6aabe16c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "splitter_pt = 10000\n",
        "x_train, x_valid, y_train, y_valid = x_train[:splitter_pt], x_train[splitter_pt:], y_train[:splitter_pt], y_train[splitter_pt:]\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(30479, 32, 32, 3)\n",
            "(10000, 17)\n",
            "(30479, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE-Zl31qpzr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "#import tensorflow_docs as tfdocs\n",
        "#import tensorflow_docs.modeling\n",
        "#import tensorflow_docs.plots\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "from keras.preprocessing import image\n",
        "import urllib.request\n",
        "from keras.preprocessing.image import *\n",
        "import keras\n",
        "from keras.layers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7G-_OQepYuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def amazonmodel():\n",
        "  am = keras.models.Sequential()\n",
        "  am.add(Conv2D(64, (3, 3), input_shape=(32, 32, 3),activation='relu'))\n",
        "  am.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  am.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  am.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  am.add(Flatten())\n",
        "  am.add(Dense(units=128, activation='relu'))\n",
        "  am.add(Dropout(0.5))\n",
        "  am.add(Dense(units=17, activation='sigmoid'))\n",
        "  return am"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFOCntHM-TYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import os\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIbov5d2-ZIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW4tggg3pp4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=amazonmodel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTWXSAjup3EU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0M3tlNM-cAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2YmqxKsqJQ6",
        "colab_type": "code",
        "outputId": "feb8d5a1-66c1-40b3-a0f5-8c3ca06f3600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, validation_data=(x_valid, y_valid), callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 30479 samples\n",
            "Epoch 1/15\n",
            "10000/10000 [==============================] - 2s 200us/step - loss: 0.3451 - accuracy: 0.8715 - val_loss: 0.2473 - val_accuracy: 0.9054\n",
            "Epoch 2/15\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.2587 - accuracy: 0.9028 - val_loss: 0.2313 - val_accuracy: 0.9093\n",
            "Epoch 3/15\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.2405 - accuracy: 0.9082 - val_loss: 0.2210 - val_accuracy: 0.9123\n",
            "Epoch 4/15\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.2301 - accuracy: 0.9124 - val_loss: 0.2132 - val_accuracy: 0.9172\n",
            "Epoch 5/15\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.2241 - accuracy: 0.9146 - val_loss: 0.2094 - val_accuracy: 0.9183\n",
            "Epoch 6/15\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 0.2193 - accuracy: 0.9153 - val_loss: 0.2084 - val_accuracy: 0.9172\n",
            "Epoch 7/15\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.2151 - accuracy: 0.9164 - val_loss: 0.2075 - val_accuracy: 0.9179\n",
            "Epoch 8/15\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 0.2128 - accuracy: 0.9171 - val_loss: 0.2019 - val_accuracy: 0.9195\n",
            "Epoch 9/15\n",
            "10000/10000 [==============================] - 2s 174us/step - loss: 0.2087 - accuracy: 0.9176 - val_loss: 0.2006 - val_accuracy: 0.9196\n",
            "Epoch 10/15\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.2063 - accuracy: 0.9190 - val_loss: 0.1994 - val_accuracy: 0.9186\n",
            "Epoch 11/15\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 0.2041 - accuracy: 0.9193 - val_loss: 0.1973 - val_accuracy: 0.9191\n",
            "Epoch 12/15\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.2010 - accuracy: 0.9202 - val_loss: 0.1935 - val_accuracy: 0.9215\n",
            "Epoch 13/15\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.1996 - accuracy: 0.9211 - val_loss: 0.1938 - val_accuracy: 0.9235\n",
            "Epoch 14/15\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.1973 - accuracy: 0.9214 - val_loss: 0.1932 - val_accuracy: 0.9245\n",
            "Epoch 15/15\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.1968 - accuracy: 0.9223 - val_loss: 0.1880 - val_accuracy: 0.9247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f9457379ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiTogGdzvTD8",
        "colab_type": "code",
        "outputId": "676082c6-a2e7-4fa0-8e80-3b58b9b451ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "pip install -U tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorboard in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpqpEv-xO1sP",
        "colab_type": "text"
      },
      "source": [
        "Upload logs onto tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeCUQmHl_G5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tensorboard dev upload --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VVfyBBGQOzE",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameter Tuning:**\n",
        "\n",
        "Techniques like tuning batch size in iterative gradiant descent and number of epochs while training.\n",
        "\n",
        "- Can Tune learning Rate.\n",
        "\n",
        "- Can tune Network Weight Initialization\n",
        "\n",
        "- Activation Function\n",
        "\n",
        "- Dropout regularization\n",
        "\n",
        "- Number of neurons in hidden layer\n",
        "\n",
        "Would Implement few for the am model\n",
        "\n",
        "Note: Have tried improving accuracy by:\n",
        "\n",
        "- adding 2 additional dense layers\n",
        "\n",
        "- changing batch size 32->64->32\n",
        "\n",
        "-loss functions: mean_squared_error and binary_crossentropy\n",
        "\n",
        "- used various optimizers like SGD, Adadelta, RMSProp, AdaMax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__7mKM36RV3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def amazonmodel2():\n",
        "  am = keras.models.Sequential()\n",
        "  am.add(Conv2D(64, (3, 3), input_shape=(32, 32, 3),activation='relu'))\n",
        "  am.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  am.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  am.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  am.add(Flatten())\n",
        "  am.add(Dense(units=256, activation='relu'))\n",
        "  am.add(Dropout(0.5))\n",
        "  am.add(Dense(units=128, activation='relu'))\n",
        "  am.add(Dropout(0.5))\n",
        "  am.add(Dense(units=128, activation='relu'))\n",
        "  am.add(Dropout(0.5))\n",
        "  am.add(Dense(units=17, activation='sigmoid'))\n",
        "  return am"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19YT1-a8SNB2",
        "colab_type": "code",
        "outputId": "8fa98cdc-f9a8-4569-9c15-6059b9d09276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "model=amazonmodel2()\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "amazonmodel = model.fit(x_train, y_train,batch_size=128,epochs=15,verbose=1,validation_data=(x_valid, y_valid),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 30479 samples\n",
            "Epoch 1/15\n",
            "10000/10000 [==============================] - 2s 197us/step - loss: 0.6866 - accuracy: 0.5874 - val_loss: 0.6757 - val_accuracy: 0.8458\n",
            "Epoch 2/15\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 0.6675 - accuracy: 0.7170 - val_loss: 0.6539 - val_accuracy: 0.8654\n",
            "Epoch 3/15\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.6436 - accuracy: 0.7551 - val_loss: 0.6206 - val_accuracy: 0.8635\n",
            "Epoch 4/15\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 0.6025 - accuracy: 0.7676 - val_loss: 0.5493 - val_accuracy: 0.8452\n",
            "Epoch 5/15\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 0.5268 - accuracy: 0.7921 - val_loss: 0.4230 - val_accuracy: 0.8838\n",
            "Epoch 6/15\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.4441 - accuracy: 0.8311 - val_loss: 0.3395 - val_accuracy: 0.9053\n",
            "Epoch 7/15\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 0.4002 - accuracy: 0.8562 - val_loss: 0.3133 - val_accuracy: 0.9053\n",
            "Epoch 8/15\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.3756 - accuracy: 0.8697 - val_loss: 0.3018 - val_accuracy: 0.9053\n",
            "Epoch 9/15\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.3624 - accuracy: 0.8746 - val_loss: 0.2957 - val_accuracy: 0.9053\n",
            "Epoch 10/15\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.3507 - accuracy: 0.8806 - val_loss: 0.2909 - val_accuracy: 0.9053\n",
            "Epoch 11/15\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.3402 - accuracy: 0.8842 - val_loss: 0.2863 - val_accuracy: 0.9053\n",
            "Epoch 12/15\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.3342 - accuracy: 0.8860 - val_loss: 0.2828 - val_accuracy: 0.9053\n",
            "Epoch 13/15\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.3279 - accuracy: 0.8891 - val_loss: 0.2800 - val_accuracy: 0.9053\n",
            "Epoch 14/15\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.3221 - accuracy: 0.8896 - val_loss: 0.2756 - val_accuracy: 0.9053\n",
            "Epoch 15/15\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 0.3157 - accuracy: 0.8918 - val_loss: 0.2720 - val_accuracy: 0.9053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95VDKHPRTF9T",
        "colab_type": "text"
      },
      "source": [
        "It is observed that the accuracy remained constant over all epochs nearly. hence trying with different batchsize, epochs and also the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys5GlbVkTCYy",
        "colab_type": "code",
        "outputId": "3e42c46d-0a7a-400e-a5f7-8ef2e972077e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model1=amazonmodel2()\n",
        "model1.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "amazonmodel = model1.fit(x_train, y_train,batch_size=32,epochs=10,verbose=1,validation_data=(x_valid, y_valid),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 30479 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2766 - accuracy: 0.8967 - val_loss: 0.2260 - val_accuracy: 0.9108\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 4s 419us/step - loss: 0.2257 - accuracy: 0.9114 - val_loss: 0.2358 - val_accuracy: 0.9118\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.2097 - accuracy: 0.9157 - val_loss: 0.1911 - val_accuracy: 0.9241\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 4s 419us/step - loss: 0.2013 - accuracy: 0.9192 - val_loss: 0.1863 - val_accuracy: 0.9251\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 4s 416us/step - loss: 0.1953 - accuracy: 0.9229 - val_loss: 0.1865 - val_accuracy: 0.9252\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.1911 - accuracy: 0.9245 - val_loss: 0.1784 - val_accuracy: 0.9291\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1878 - accuracy: 0.9263 - val_loss: 0.1725 - val_accuracy: 0.9322\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1857 - accuracy: 0.9274 - val_loss: 0.1948 - val_accuracy: 0.9240\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1844 - accuracy: 0.9278 - val_loss: 0.1745 - val_accuracy: 0.9297\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.1847 - accuracy: 0.9285 - val_loss: 0.1782 - val_accuracy: 0.9290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMhTGHS_YaUh",
        "colab_type": "code",
        "outputId": "f5dc6a6a-3df4-4493-9b81-2563ad364ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model2=amazonmodel2()\n",
        "model2.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "amazonmodel2 = model2.fit(x_train, y_train,batch_size=64,epochs=10,verbose=1,validation_data=(x_valid, y_valid),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 30479 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 3s 294us/step - loss: 0.3015 - accuracy: 0.8898 - val_loss: 0.2385 - val_accuracy: 0.9053\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.2455 - accuracy: 0.9061 - val_loss: 0.2232 - val_accuracy: 0.9096\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.2283 - accuracy: 0.9095 - val_loss: 0.2063 - val_accuracy: 0.9165\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 263us/step - loss: 0.2155 - accuracy: 0.9119 - val_loss: 0.1968 - val_accuracy: 0.9183\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 0.2085 - accuracy: 0.9143 - val_loss: 0.1890 - val_accuracy: 0.9210\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 0.2010 - accuracy: 0.9182 - val_loss: 0.2207 - val_accuracy: 0.9106\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 263us/step - loss: 0.1965 - accuracy: 0.9201 - val_loss: 0.1810 - val_accuracy: 0.9272\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 0.1923 - accuracy: 0.9220 - val_loss: 0.1828 - val_accuracy: 0.9255\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 262us/step - loss: 0.1878 - accuracy: 0.9245 - val_loss: 0.1941 - val_accuracy: 0.9214\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 0.1860 - accuracy: 0.9258 - val_loss: 0.1754 - val_accuracy: 0.9316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDVVvWKkUvZc",
        "colab_type": "code",
        "outputId": "5045e450-6593-4aaa-ce8a-48327533e0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "!tensorboard dev upload --logdir logs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-05 06:17:26.646622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Data for the \"graphs\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "Upload started and will continue reading any new data as it's added\n",
            "to the logdir. To stop uploading, press Ctrl-C.\n",
            "View your TensorBoard live at: https://tensorboard.dev/experiment/KbkQ8gTYRMKOmpcwexSqEA/\n",
            "E0505 06:17:30.676089 140252155189120 uploader.py:770] Attempted to re-upload existing blob.  Skipping.\n",
            "E0505 06:17:31.627651 140252155189120 uploader.py:770] Attempted to re-upload existing blob.  Skipping.\n",
            "E0505 06:17:32.659365 140252155189120 uploader.py:770] Attempted to re-upload existing blob.  Skipping.\n",
            "\n",
            "Upload stopped. View your TensorBoard at https://tensorboard.dev/experiment/KbkQ8gTYRMKOmpcwexSqEA/\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hFsnRT3U16R",
        "colab_type": "code",
        "outputId": "91f86a4c-6414-47a9-b655-0b2f45afe235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!tensorboard dev update-metadata --experiment_id 'KbkQ8gTYRMKOmpcwexSqEA' --name \"Amazonmodel\" --description \"Hyperparameter Tuning(Amazon Dataset)\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-05 06:20:29.543846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Data for the \"graphs\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
